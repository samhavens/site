<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Sam Havens — Resume</title>
<meta content="Sam Havens — machine learning researcher, engineer, and manager. Resume." name="description"/>
<style>
    :root { --maxw: 900px; --fg: #111; --muted: #444; --rule: #e5e5e5; }
    html, body { margin: 0; padding: 0; }
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      color: var(--fg);
      line-height: 1.45;
      max-width: var(--maxw);
      margin: 32px auto;
      padding: 0 16px 48px;
      font-size: 16px;
    }
    a { color: inherit; }
    a:hover { text-decoration: underline; }
    h1 { font-size: 34px; margin: 0 0 6px; letter-spacing: -0.02em; }
    .tagline { margin: 0; color: var(--muted); }
    .contact { margin: 10px 0 18px; color: var(--muted); }
    hr { border: 0; border-top: 1px solid var(--rule); margin: 22px 0; }
    h2 { font-size: 20px; margin: 22px 0 10px; text-transform: uppercase; letter-spacing: 0.08em; }
    h3 { font-size: 17px; margin: 16px 0 4px; }
    .roleline { margin: 0 0 8px; color: var(--muted); }
    ul { margin: 8px 0 0 20px; padding: 0; }
    li { margin: 6px 0; }
    .small { font-size: 14px; color: var(--muted); }
    .grid { display: grid; grid-template-columns: 1fr; gap: 10px; }
    @media (min-width: 760px) { .grid { grid-template-columns: 1fr 1fr; gap: 18px; } }
    @media print {
      body { margin: 0; max-width: none; padding: 0 0 0; font-size: 12px; }
      a { text-decoration: none; }
      h1 { font-size: 22px; }
      h2 { font-size: 12px; }
      h3 { font-size: 12px; }
      hr { margin: 14px 0; }
    }
  </style>
</head>
<body>
<h1>Sam Havens</h1>
<p class="tagline">Machine Learning Researcher, Engineer, &amp; Manager | Portland, Oregon</p>
<p class="contact">
<a href="https://www.linkedin.com/in/samhavens">linkedin.com/in/samhavens</a>
     |  <a href="mailto:samhavens@gmail.com">samhavens@gmail.com</a>
     |  818.590.0484
     |  <a href="https://scholar.google.com/citations?hl=en&amp;user=3WXWL3UAAAAJ">Google Scholar</a>
     |  <a href="https://dblp.org/pid/361/7360">DBLP</a>
</p><hr/>
<h2>Work Experience</h2>
<h3><a href="https://www.databricks.com/">Databricks</a> — Staff Research Scientist</h3>
<p class="roleline">Jul 2023 – Present</p>
<ul><li>Led post-training for DBRX / DBRX-Instruct (instruction tuning + preference optimization) and drove cross-team release execution.</li><li>Built the internal agent harness (evaluation, regression testing, tool-use simulation) and productionalized it for multiple teams.</li><li>Developed continual learning and agent memory techniques (e.g., never-ending learning pipelines; memory-augmented judging/evaluation).</li><li>Built and published evaluation &amp; benchmarking for agentic retrieval, long-context context management, tool use, LLM-as-judge, and grounded reasoning (see publications and writing below).</li></ul>
<h3><a href="https://www.mosaicml.com/">MosaicML</a> — Research Scientist</h3>
<p class="roleline">Sep 2022 – Jul 2023</p>
<ul>
<li>Led the development of chat/instruction-tuned variants of MPT-7B and MPT-30B, enhancing usability for downstream applications.</li>
<li><strong>MosaicBERT</strong>: Developed a BERT-style encoder architecture and training recipe optimized for fast pretraining (FlashAttention, ALiBi, GLU, dynamic padding removal, low precision LayerNorm).</li>
<li><strong>LIMIT</strong>: Investigated the impact of small, high-quality instruction fine-tuning datasets on LLMs across traditional NLP benchmarks and model-based evaluation.</li>
</ul>
<h3><a href="https://writer.com/">Writer</a> — Director of NLP Engineering</h3>
<p class="roleline">Sep 2020 – Sep 2022</p>
<p class="small">Writer is an AI writing assistant used by brands like Twitter, Intuit, and Accenture. The NLP team used a microservice architecture based on Kubernetes, FastAPI, HuggingFace Transformers, NVIDIA Triton, and ONNX.</p>
<ul>
<li>Responsible for NLP from research to operations, including &gt;25 microservices.</li>
<li>Trained an encoder/decoder Grammar Error Correction model using novel synthetic data techniques, outperforming an open-source baseline by 130%.</li>
<li>Served a character-based transformer spelling correction model via Triton/ONNX with inference latencies below 300ms at 50 req/s.</li>
</ul>
<h3><a href="https://qordoba.com/">Qordoba</a> — Director of Data Science</h3>
<p class="roleline">Feb 2019 – Sep 2020</p>
<ul>
<li>Reduced mean service latency from &gt;1.5s to &lt;300ms.</li>
<li>Grew team from 2 to 6 while improving onboarding effectiveness (time to first commit: from weeks to &lt; 1 day).</li>
<li>Implemented classification and seq2seq models in spaCy, Flair, and Marian with aggressive latency requirements.</li>
<li>Responsible for all ML Ops; productionized models via modern async/await Python, Docker/Kubernetes/PubSub, plus Bash and Jenkins.</li>
</ul>
<h3><a href="https://carlabs.com/">CarLabs</a> — Chief Technology Officer</h3>
<p class="roleline">May 2016 – Jan 2019</p>
<ul>
<li>Created a suite of tools for automotive OEMs and dealers to manage chatbots across web, chat, and voice.</li>
<li>Used Docker/Kubernetes to operate services written in Node.js, Elixir, and Python; models in FastText and TensorFlow.</li>
<li>Engineering team grew from 4 to 16 during my tenure; established a culture of testing, code reviews, pair programming, and mentorship.</li>
</ul>
<h3><a href="https://carlabs.com/">CarLabs</a> — Software Engineer</h3>
<p class="roleline">Mar 2015 – May 2016</p>
<ul>
<li>Created a car comparison shopping tool using React, ES6, Webpack, and MaterialUI.</li>
<li>Built a conversational agent with a Node.js/Docker backend and NLP services in Python using FastText, NLTK, and Gensim.</li>
</ul>






<hr/>
<h2>Selected Publications &amp; Preprints</h2>
<ul>
<li><strong>FreshStack: Realistic Benchmarks for Agentic Retrieval on Technical Documents.</strong> arXiv:2504.13128 (2025). <a href="https://arxiv.org/abs/2504.13128">arXiv</a></li>
<li><strong>Long-context Context Management Performance of Large Language Models.</strong> arXiv:2411.03538 (2024). <a href="https://arxiv.org/abs/2411.03538">arXiv</a></li>
<li><strong>LoRA Learns Less and Forgets Less.</strong> TMLR (2024). <a href="https://arxiv.org/abs/2405.09673">arXiv</a>  |  <a href="https://openreview.net/forum?id=aloEru2qCG">OpenReview</a></li>
<li><strong>MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining.</strong> NeurIPS (2023). <a href="https://arxiv.org/abs/2312.17482">arXiv</a>  |  <a href="https://neurips.cc/virtual/2023/poster/72778">NeurIPS</a></li>
<li><strong>LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms.</strong> arXiv:2311.13133 (2023). <a href="https://arxiv.org/abs/2311.13133">arXiv</a></li>
</ul>
<hr/>
<h2>Technical Writing</h2>
<p class="small">
    Full list: <a href="https://www.databricks.com/blog/author/sam-havens">Databricks blog author page</a>.
  </p>
<ul>
<li><strong>MemAlign: Building Better LLM Judges From Human Feedback with Scalable Memory.</strong> (Feb 3, 2026) <a href="https://www.databricks.com/blog/memalign-building-better-llm-judges-human-feedback-scalable-memory">post</a></li>
<li><strong>Introducing OfficeQA: A Benchmark for End-to-End Grounded Reasoning.</strong> (Dec 9, 2025) <a href="https://www.databricks.com/blog/introducing-officeqa-benchmark-end-to-end-grounded-reasoning">post</a></li>
<li><strong>Agent Learning from Human Feedback (ALHF): A Databricks Knowledge Assistant Case Study.</strong> (Aug 4, 2025) <a href="https://www.databricks.com/blog/agent-learning-human-feedback-alhf-databricks-knowledge-assistant-case-study">post</a></li>
<li><strong>Embedding Model Finetuning for Agentic Retrieval.</strong> (Feb 20, 2025) <a href="https://www.databricks.com/blog/improving-retrieval-and-rag-embedding-model-finetuning">post</a></li>
<li><strong>The Power of Fine-Tuning on Your Data: Quick Fixing Bugs with LLMs via Never Ending Learning (NEL).</strong> (Apr 8, 2025) <a href="https://www.databricks.com/blog/power-fine-tuning-your-data-quick-fixing-bugs-llms-never-ending-learning-nel">post</a></li>
<li><strong>Evaluating Long-context Context Management (OpenAI o1 vs Google Gemini).</strong> (Oct 8, 2024) <a href="https://www.databricks.com/blog/long-context-rag-capabilities-openai-o1-and-google-gemini">post</a></li>
<li><strong>Beyond the Leaderboard: Unpacking Function Calling Evaluation.</strong> (Aug 16, 2024) <a href="https://www.databricks.com/blog/unpacking-function-calling-eval">post</a></li>
<li><strong>Long-context Context Management Performance of LLMs.</strong> (Aug 12, 2024) <a href="https://www.databricks.com/blog/long-context-rag-performance-llms">post</a></li>
</ul>








</body>
</html>
